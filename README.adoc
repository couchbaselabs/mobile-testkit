[%hardbreaks]
:toc: left
:toclevels: 3

This repository contains Mobile QE Functional / Integration tests. 

```
$ git clone https://github.com/couchbaselabs/mobile-testkit.git
$ cd mobile-testkit/
```

== Repo Structure

The repo structure is the following:

* libraries
 * keywords (new devopement, will be renamed to testkit in the near future)
 * provision
 * testkit (legacy)
 * utilities

* testsuites
 * listener
 * syncgateway

== Mobile Testkit Dependencies
link:docs/dependencies.md[Instructions]

== Development Environment
link:docs/devenv.md[Instructions]

== Running Mobile-Testkit Framework Unit Tests

Below is an example on how to run mobile testkit framework unit tests

```
pytest libraries/provision/test_install_sync_gateway.py
```

== Sync Gateway Tests

The sync_gateway tests require targeting different cluster topologies of sync_gateway(s) + Couchbase Server(s). Don't worry! We will set this up for you. There are a few options for these cluster nodes. You can use EC2 AWS instances, docker (Sequoia) or local vms (vagrant).

The sync_gateway tests use https://www.ansible.com/[Ansible] to provision the clusters.  

=== Using Sequoia for Provisioning 
link:docs/sequoia.adoc[Instructions]

=== Using AWS for Provisioning
link:docs/aws.adoc[Instructions]

=== Using Vagrant for Provisioning
link:docs/vagrant.adoc[Instructions]

=== Ansible Setup
link:docs/ansible.adoc[Instructions]

=== Functional Tests

link:testsuites/syncgateway/functional/tests/README.md[Running Functional Tests]

=== System Tests

link:testsuites/syncgateway/system/README.md[Running System Tests]

=== Performance Tests
link:testsuites/syncgateway/performance/README.md[Running Performance Tests]

=== Collecting Sync Gateway logs

```
$ python libraries/utilities/fetch_sg_logs.py
```

<<<<<<< HEAD
If you plan on doing development, it may be helpful to add the PYTHONPATH env variables to your .bashrc file so that you do not have to run this setup everytime you open a new shell.

== Development Environment

=== PyCharm

You may use what ever environment you would like, however https://www.jetbrains.com/pycharm/[PyCharm] is a very good option. There are a couple steps required to get going with this IDE if you choose to use it. 

==== Set Interpreter and Library Home

- Go to PyCharm -> Preferences
- Expand Project: mobile-testkit and select Project Interpreter
- From the dropdown, make sure your venv (created above) is selected
- Click Apply
- Click on the gear next to the interpreter
- Select More ...
- Make sure your virtualenv is selected and click on the directory icon on the bottom (Show Paths for Selected Interpreter)
- Click the plus icon and find the path to mobile-testkit/
- Select libraries from inside the repo directory
- Click OK, OK, Apply

Now PyCharm should recognize the custom libraries and provide intellisense.

=== Android
- Open Andrond Studio 
- Open the code of mobile-testkit/app/testkit.java/Testkit.java.Android/Tests/AndroidClient2
- Build the app
- Run the app
- If any changes made to the Android code, make sure you run the following
-- Lint the code : Analyze -> Inspect code
--- https://developer.android.com/studio/write/lint.html
-- Code styles and format code : Code -> Reformat Code

== Listener Tests

The listener tests are a series of tests utilizing Couchbase Lite Listener via LiteServ and Sync Gateway or P2P. They are meant to be cross platform and should be able to run for
for all the platforms that expose the Listener (Mac OSX, .NET, Android, iOS)

Make sure you have a Sync Gateway + Couchbase server running:
See above for provisioning

link:testsuites/listener/README.md[Instructions]

=== Listener Test Excecution (Client + Client (P2P))

link:testsuites/listener/shared/client_client/README.md[Running Tests]

=== Listener Test Excecution (Client + SG)

link:testsuites/listener/shared/client_sg/README.md[Running Tests]

=== Android Emulator Setup
link:docs/androidsetup.adoc[Instructions]

== Debugging

Thanks to pytest, you can break into pdb very easily

```
import pdb

for thing in things:
    pdb.set_trace()
    # break here ^
    thing.do()
```

If you want the test to drop into pdb at the point of failure, you can execute the test with the flag

```
pytest --pdb
```


== Monitoring

=== Monitoring Clusters
link:docs/Monitoring[Monitoring Tool]
